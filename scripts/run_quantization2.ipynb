{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from fpga_nn_backend.datasets import *\n",
    "from fpga_nn_backend.training import *\n",
    "from fpga_nn_backend.evaluation import *\n",
    "from fpga_nn_backend.models.relu_toy_models import *\n",
    "from fpga_nn_backend.quantization import *\n",
    "from fpga_nn_backend.fpga_simple.emulation import *\n",
    "from fpga_nn_backend.fpga_simple.conversion import *\n",
    "from fpga_nn_backend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467669b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.10.0\n",
      "Torchvision Version: 0.11.1\n",
      "WARNING: Could not find GPU! Using CPU only\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebc2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = get_rel_pkg_path(\"dataset/\")\n",
    "weights_dir = get_rel_pkg_path(\"weights/\")\n",
    "session_dir = get_rel_pkg_path(\"sessions/\")\n",
    "models_dir = get_rel_pkg_path(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2143ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = ImageDatasetType.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bc6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_datasets = get_img_dataset(data_dir, dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6501354",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = apply_img_transforms(orig_datasets, dataset_type, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b031d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(datasets, 128, 128, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0769d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = IMG_DATASET_TO_IMG_SIZE_FLAT[dataset_type]\n",
    "num_classes = IMG_DATASET_TO_NUM_CLASSES[dataset_type]\n",
    "\n",
    "model = ReLUToyModel(input_dim, num_classes, layer_dims=[])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197f117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d09605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 10]           7,840\n",
      "      ReLUToyModel-3                   [-1, 10]               0\n",
      "       DeQuantStub-4                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 7,840\n",
      "Trainable params: 7,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f2857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-18-2021 11-04-36 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a69c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-20-2021 06-39-40 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6f35ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 12-07-2021 11-47-53 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_loss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0be415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.85it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "qconfig = torch.quantization.QConfig(\n",
    "    activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8),\n",
    "    weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8))\n",
    "#qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model.qconfig = qconfig\n",
    "#torch.quantization.fuse_modules(model.model.layers, [['0', '1'], ['2', '3'], ['4', '5'], ['6', '7']], inplace=True)\n",
    "model = torch.quantization.prepare(model)\n",
    "stats = get_dataloader_stats(dataloaders['test'], model, criterion, device)\n",
    "model_int8 = torch.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01a60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9034\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ea8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantWrapper(\n",
       "  (model): ReLUToyModel(\n",
       "    (layers): Sequential(\n",
       "      (0): QuantizedLinear(in_features=784, out_features=10, scale=0.10827332735061646, zero_point=125, qscheme=torch.per_tensor_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0039]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca02df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -8, -23, -24,  ..., -19,  -7,  -9],\n",
       "        [-18, -23, -17,  ..., -20, -17, -19],\n",
       "        [ -4, -24, -24,  ..., -14, -15,  -7],\n",
       "        ...,\n",
       "        [-19, -24,  -8,  ..., -17,  -7, -22],\n",
       "        [ -4, -10,  -7,  ..., -16,  -7, -22],\n",
       "        [-21, -12, -11,  ...,  -7,  -5, -14]], dtype=torch.int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0].weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d607edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0207, -0.0310, -0.0344,  ..., -0.0172,  0.0241,  0.0172],\n",
       "        [-0.0138, -0.0310, -0.0103,  ..., -0.0207, -0.0103, -0.0172],\n",
       "        [ 0.0344, -0.0344, -0.0344,  ...,  0.0000, -0.0034,  0.0241],\n",
       "        ...,\n",
       "        [-0.0172, -0.0344,  0.0207,  ..., -0.0103,  0.0241, -0.0276],\n",
       "        [ 0.0344,  0.0138,  0.0241,  ..., -0.0069,  0.0241, -0.0276],\n",
       "        [-0.0241,  0.0069,  0.0103,  ...,  0.0241,  0.0310,  0.0000]],\n",
       "       size=(10, 784), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.003444838570430875,\n",
       "       zero_point=-14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0].weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0926ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:02<00:00, 26.75it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = get_dataloader_stats(dataloaders['test'], model_int8, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f595a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9009\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ba5487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get_param(param):\n",
    "    if param is not None:\n",
    "        return param.int_repr().numpy()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5dbd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_nn = ConvertedNN((1, 28, 28))\n",
    "\n",
    "converted_nn.add_flatten_layer((1, 28, 28), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((784,), (10,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[0].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[0].bias()))\n",
    "\n",
    "converted_nn.add_output_layer((10,), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fea43ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedLinear(in_features=784, out_features=10, scale=0.10827332735061646, zero_point=125, qscheme=torch.per_tensor_affine)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e1ab99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_nn.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1877a245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'layer_type': <ConverterLayerType.FLATTEN: 5>,\n",
       "   'input_shapes': ((1, 28, 28),),\n",
       "   'output_shape': (784,),\n",
       "   'output_size': 784,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <ConverterLayerType.DENSE: 0>,\n",
       "   'input_shapes': ((784,),),\n",
       "   'output_shape': (10,),\n",
       "   'output_size': 10,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <ConverterLayerType.OUTPUT: 7>,\n",
       "   'input_shapes': ((10,),),\n",
       "   'output_shape': (10,),\n",
       "   'output_size': 10,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_nn.get_layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f24c45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.coe\", 'w') as f:\n",
    "    f.write(converted_nn.generate_parameter_coe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e32910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator = FPGAEmulator(converted_nn, bram_reserved_size=303000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "530cab97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': (1, 28, 28),\n",
       " 'inital_input_addr': 0,\n",
       " 'layers': [{'layer_type': <LayerType.DENSE: 0>,\n",
       "   'config': {'has_bias': None,\n",
       "    'input_base_addr': 0,\n",
       "    'weight_base_addr': 0,\n",
       "    'bias_base_addr': 0,\n",
       "    'output_base_addr': 784,\n",
       "    'm_size': 10,\n",
       "    'chw_size': 784}},\n",
       "  {'layer_type': <LayerType.MOVE: 5>,\n",
       "   'config': {'input_base_addr': 784, 'output_base_addr': 0, 'n_size': 10}},\n",
       "  {'layer_type': <LayerType.OUTPUT: 6>,\n",
       "   'config': {'output_base_addr': 0, 'n_size': 10}}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator.exec_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a5fdd56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  58  62  85 127 127  75  46   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  84 126 126 126 126\n",
      " 126 126 109  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  84 126 126 126 106  71  88 126 126  61   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  26 125 126 105  16\n",
      "   6   0   3 103 126  70   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  38 125 105  12   0   0   0  61 124 126  32   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   9\n",
      "   0   0   0   0 104 126 126  32   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  58 123 126  99   5\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  38 123 126 115  31   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  64 126 126  72\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  88 123 126  79   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12 117 126 116\n",
      "  17   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  99 126 126  70   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  39 124 126\n",
      "  94   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   9 100 126 126  70   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  67 126\n",
      " 126  86   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 124 126 126  12   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 124 126 126  21  10  10  10  10   2   0   2  10  10  18  75  75  75  73\n",
      "   5   0   0   0   0   0   0   0   0   0 124 126 126 126 126 126 126 126\n",
      "  84  71  83 126 126 126 126 126 126 126  61   0   0   0   0   0   0   0\n",
      "   0   0  87 126 126 126 126 126 126 126 126 126 126 126 124 123 123  84\n",
      "  58  58  28   0   0   0   0   0   0   0   0   0   0  59  61  61  61  83\n",
      " 126 126 126  77  61  61  20   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for imgs, labels in dataloaders['test']:\n",
    "    break\n",
    "data = (imgs[index] * 255).numpy()\n",
    "data = (data/2).astype(np.int8)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cafc3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 784)]\n"
     ]
    }
   ],
   "source": [
    "parameters = converted_nn.parameters_info['parameters']\n",
    "print([p.shape for p in parameters])\n",
    "\n",
    "def dense_no_bias(w, i):\n",
    "    pass\n",
    "\n",
    "def relu(i):\n",
    "    return np.maximum(0, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32b3ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_per_layer = {}\n",
    "outputs_per_layer = {}\n",
    "def get_output(name):\n",
    "    def hook(model, input, output):\n",
    "        inputs_per_layer[name] = input\n",
    "        outputs_per_layer[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "hooks = {}\n",
    "for name, module in model_int8.named_modules():\n",
    "    hooks[name] = module.register_forward_hook(get_output(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbed750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = imgs[None, index, :]\n",
    "model_out = model_int8(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89f47bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['quant', 'model.layers.0', 'model.layers', 'model', 'dequant', ''])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_per_layer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40e4de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116, 125, 171, 255,\n",
       "         255, 150,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 253,\n",
       "         253, 253, 218,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 213, 142,\n",
       "         176, 253, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,  52, 250, 253, 210,  32,  12,   0,\n",
       "           6, 206, 253, 140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,  77, 251, 210,  25,   0,   0,   0,\n",
       "         122, 248, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,  31,  18,   0,   0,   0,   0,\n",
       "         209, 253, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 117,\n",
       "         247, 253, 198,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76, 247,\n",
       "         253, 231,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 253,\n",
       "         253, 144,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 176, 246, 253,\n",
       "         159,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 234, 253, 233,\n",
       "          35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 253, 141,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 248, 253, 189,  12,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,  19, 200, 253, 253, 141,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 253, 173,  12,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  25,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  43,  20,  20,\n",
       "          20,  20,   5,   0,   5,  20,  20,  37, 150, 150, 150, 147,  10,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253, 253, 253, 253,\n",
       "         253, 253, 168, 143, 166, 253, 253, 253, 253, 253, 253, 253, 123,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0, 174, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 253, 253, 253, 249, 247, 247, 169, 117, 117,  57,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 123, 123, 123, 166,\n",
       "         253, 253, 253, 155, 123, 123,  41,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_per_layer['model.layers.0'][0].int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80c80bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[147, 112, 185, 151,  70, 151, 161,  66, 144,  79]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_per_layer['model.layers.0'].int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57ea1844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0207, -0.0310, -0.0344,  ..., -0.0172,  0.0241,  0.0172],\n",
       "        [-0.0138, -0.0310, -0.0103,  ..., -0.0207, -0.0103, -0.0172],\n",
       "        [ 0.0344, -0.0344, -0.0344,  ...,  0.0000, -0.0034,  0.0241],\n",
       "        ...,\n",
       "        [-0.0172, -0.0344,  0.0207,  ..., -0.0103,  0.0241, -0.0276],\n",
       "        [ 0.0344,  0.0138,  0.0241,  ..., -0.0069,  0.0241, -0.0276],\n",
       "        [-0.0241,  0.0069,  0.0103,  ...,  0.0241,  0.0310,  0.0000]],\n",
       "       size=(10, 784), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.003444838570430875,\n",
       "       zero_point=-14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0].weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7296b147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0207, -0.0310, -0.0344,  ..., -0.0172,  0.0241,  0.0172],\n",
       "        [-0.0138, -0.0310, -0.0103,  ..., -0.0207, -0.0103, -0.0172],\n",
       "        [ 0.0344, -0.0344, -0.0344,  ...,  0.0000, -0.0034,  0.0241],\n",
       "        ...,\n",
       "        [-0.0172, -0.0344,  0.0207,  ..., -0.0103,  0.0241, -0.0276],\n",
       "        [ 0.0344,  0.0138,  0.0241,  ..., -0.0069,  0.0241, -0.0276],\n",
       "        [-0.0241,  0.0069,  0.0103,  ...,  0.0241,  0.0310,  0.0000]],\n",
       "       size=(10, 784), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.003444838570430875,\n",
       "       zero_point=-14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0].weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbc8b70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 98, 183, 177, 156, 127, 249, 179,  74,  42,  95], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(parameters[0] @ data).astype(np.uint8) - 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a557ed9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_bias': None, 'input_base_addr': 0, 'weight_base_addr': 0, 'bias_base_addr': 0, 'output_base_addr': 784, 'm_size': 10, 'chw_size': 784}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahir\\Documents\\Code Repositories\\6111-fpga-final-project\\fpga_nn_backend\\fpga_simple\\emulation.py:176: RuntimeWarning: overflow encountered in byte_scalars\n",
      "  o_out[i] = np.int8(w_in[i] * i_in[i] + b_in[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_base_addr': 784, 'output_base_addr': 0, 'n_size': 10}\n",
      "{'output_base_addr': 0, 'n_size': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([112, 197, 191, 170, 141,   7, 193,  88,  56, 109], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator.execute(data).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62ba25ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 94,  95,  96,  97,  98,  99, 100, 121, 122, 123, 124, 125, 126,\n",
       "        127, 128, 129, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "        175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 203, 204, 205,\n",
       "        206, 210, 211, 212, 213, 232, 233, 238, 239, 240, 241, 265, 266,\n",
       "        267, 268, 269, 292, 293, 294, 295, 296, 320, 321, 322, 323, 347,\n",
       "        348, 349, 350, 351, 374, 375, 376, 377, 378, 402, 403, 404, 405,\n",
       "        429, 430, 431, 432, 433, 456, 457, 458, 459, 460, 484, 485, 486,\n",
       "        487, 488, 512, 513, 514, 515, 540, 541, 542, 543, 544, 545, 546,\n",
       "        547, 548, 550, 551, 552, 553, 554, 555, 556, 557, 558, 568, 569,\n",
       "        570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582,\n",
       "        583, 584, 585, 586, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
       "        605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 625, 626, 627,\n",
       "        628, 629, 630, 631, 632, 633, 634, 635, 636], dtype=int64),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(data > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c36f61fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.get_default_qconfig('fbgemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49b41f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "qscheme=torch.per_tensor_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "580994e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0198, -0.0296, -0.0352,  ..., -0.0172,  0.0248,  0.0179],\n",
       "        [-0.0141, -0.0304, -0.0100,  ..., -0.0219, -0.0107, -0.0176],\n",
       "        [ 0.0342, -0.0348, -0.0344,  ...,  0.0002, -0.0032,  0.0236],\n",
       "        ...,\n",
       "        [-0.0155, -0.0328,  0.0212,  ..., -0.0093,  0.0258, -0.0280],\n",
       "        [ 0.0344,  0.0141,  0.0242,  ..., -0.0077,  0.0241, -0.0263],\n",
       "        [-0.0256,  0.0069,  0.0102,  ...,  0.0229,  0.0315,  0.0013]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c399800",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = parameters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fc2cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (w.astype(np.int32) @ data.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7020138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12183.78098011, -27918.38573068,   3374.55479354, -10763.88456523,\n",
       "       -48491.18411392, -10587.50731498,  -6049.33907241, -50686.64237261,\n",
       "       -13464.87098932, -42036.36143059])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out*0.10827332735061646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "87c19650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 9, 1, 8, 0, 3, 5, 6, 2], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(out >> 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbc07662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4, 9, 1, 8, 0, 3, 5, 6, 2]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(outputs_per_layer['model.layers.0'].int_repr().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be33a1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[147, 112, 185, 151,  70, 151, 161,  66, 144,  79]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_per_layer['model.layers.0'].int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c2351d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
       "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
       "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
       "        1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7, 3, 9, 7, 4, 4, 4, 9, 2,\n",
       "        5, 4, 7, 6, 7, 9, 0, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f80c106f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3820, -1.4076,  6.4964,  2.8151, -5.9550,  2.8151,  3.8978, -6.3881,\n",
       "          2.0572, -4.9806]], size=(1, 10), dtype=torch.quint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.10827332735061646,\n",
       "       zero_point=125)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_per_layer['model.layers.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ff436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
