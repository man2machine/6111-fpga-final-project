{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from fpga_nn_backend.datasets import *\n",
    "from fpga_nn_backend.training import *\n",
    "from fpga_nn_backend.evaluation import *\n",
    "from fpga_nn_backend.models.relu_toy_models import *\n",
    "from fpga_nn_backend.quantization import *\n",
    "from fpga_nn_backend.fpga_simple.emulation import *\n",
    "from fpga_nn_backend.fpga_simple.conversion import *\n",
    "from fpga_nn_backend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467669b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.10.0\n",
      "Torchvision Version: 0.11.1\n",
      "WARNING: Could not find GPU! Using CPU only\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebc2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = get_rel_pkg_path(\"dataset/\")\n",
    "weights_dir = get_rel_pkg_path(\"weights/\")\n",
    "session_dir = get_rel_pkg_path(\"sessions/\")\n",
    "models_dir = get_rel_pkg_path(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2143ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = ImageDatasetType.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bc6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_datasets = get_img_dataset(data_dir, dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6501354",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = apply_img_transforms(orig_datasets, dataset_type, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b031d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(datasets, 128, 128, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0769d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = IMG_DATASET_TO_IMG_SIZE_FLAT[dataset_type]\n",
    "num_classes = IMG_DATASET_TO_NUM_CLASSES[dataset_type]\n",
    "\n",
    "model = ReLUToyModel(input_dim, num_classes, layer_dims=[256, 128, 64, 32])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197f117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d09605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 256]         200,704\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "            Linear-4                  [-1, 128]          32,768\n",
      "              ReLU-5                  [-1, 128]               0\n",
      "            Linear-6                   [-1, 64]           8,192\n",
      "              ReLU-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,048\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             320\n",
      "     ReLUToyModel-11                   [-1, 10]               0\n",
      "      DeQuantStub-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 244,032\n",
      "Trainable params: 244,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 0.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f2857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-18-2021 11-04-36 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a69c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-20-2021 06-39-40 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6f35ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-23-2021 02-52-17 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_loss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0be415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 20.58it/s]\n",
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "#torch.quantization.fuse_modules(model.model.layers, [['0', '1'], ['2', '3'], ['4', '5'], ['6', '7']], inplace=True)\n",
    "model = torch.quantization.prepare(model)\n",
    "stats = get_dataloader_stats(dataloaders['test'], model, criterion, device)\n",
    "model_int8 = torch.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01a60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ea8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantWrapper(\n",
       "  (model): ReLUToyModel(\n",
       "    (layers): Sequential(\n",
       "      (0): QuantizedLinear(in_features=784, out_features=256, scale=0.050842445343732834, zero_point=57, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): QuantizedLinear(in_features=256, out_features=128, scale=0.06895451247692108, zero_point=27, qscheme=torch.per_channel_affine)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): QuantizedLinear(in_features=128, out_features=64, scale=0.10227379202842712, zero_point=27, qscheme=torch.per_channel_affine)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): QuantizedLinear(in_features=64, out_features=32, scale=0.17031508684158325, zero_point=33, qscheme=torch.per_channel_affine)\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): QuantizedLinear(in_features=32, out_features=10, scale=0.40706461668014526, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca02df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24, -36,  55,  ..., -34, -51,  18],\n",
       "        [ 66, -58,  62,  ...,   5, -62, -66],\n",
       "        [ 60, -87,  -6,  ...,  66,  17, -56],\n",
       "        ...,\n",
       "        [-41, -13,  41,  ...,  39,  57, -25],\n",
       "        [-32,  66, -31,  ..., -48,   5,  49],\n",
       "        [ 57, -51,  -4,  ..., -30, -18,  -3]], dtype=torch.int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0].weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c92e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8.model.layers[8].bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0926ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 25.83it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = get_dataloader_stats(dataloaders['test'], model_int8, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f595a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6b47e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get_param(param):\n",
    "    if param is not None:\n",
    "        return param.int_repr().numpy()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5dbd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_nn = ConvertedNN((1, 28, 28))\n",
    "\n",
    "converted_nn.add_flatten_layer((1, 28, 28), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((784,), (256,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[0].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[0].bias()))\n",
    "converted_nn.add_relu_layer((256,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((256,), (128,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[2].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[2].bias()))\n",
    "converted_nn.add_relu_layer((128,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((128,), (64,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[4].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[4].bias()))\n",
    "converted_nn.add_relu_layer((64,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((64,), (32,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[6].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[6].bias()))\n",
    "converted_nn.add_relu_layer((32,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((32,), (10,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[8].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[8].bias()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fea43ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedLinear(in_features=32, out_features=10, scale=0.40706461668014526, zero_point=64, qscheme=torch.per_channel_affine)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a262d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'layer_type': <LayerType.FLATTEN: 5>,\n",
       "   'input_shape': (1, 28, 28),\n",
       "   'output_shape': (784,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'input_shape': (784,),\n",
       "   'output_shape': (256,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'input_shape': (256,),\n",
       "   'output_shape': (256,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'input_shape': (256,),\n",
       "   'output_shape': (128,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'input_shape': (128,),\n",
       "   'output_shape': (128,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'input_shape': (128,),\n",
       "   'output_shape': (64,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'input_shape': (64,),\n",
       "   'output_shape': (64,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'input_shape': (64,),\n",
       "   'output_shape': (32,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'input_shape': (32,),\n",
       "   'output_shape': (32,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'input_shape': (32,),\n",
       "   'output_shape': (10,),\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_nn.get_execution_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24c45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.coe\", 'w') as f:\n",
    "    f.write(converted_nn.generate_parameter_coe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "397b5e89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11388/3985344501.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bank_alloc_len_per_param'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'info' is not defined"
     ]
    }
   ],
   "source": [
    "info['bank_alloc_len_per_param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6210b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (np.round((datasets['train'][0][0]).reshape((28,28)).numpy()*255)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac1a0aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269ac0ab430>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOTElEQVR4nO3dX4xUdZrG8ecFBzWACtK6rRCZRWMkGhlS6Wx0gyhZ/JMocDEbMEHWGPEChUmauAQv8MILs+zMZFQysREDY0YmRKYjGrNOS4iGmCiFsi0ssrikZUCEJkTH0QsWfPeiD5sWu37VVJ2qU9Pv95N0qvo8dfq8qfBwqut098/cXQBGvlFFDwCgOSg7EARlB4Kg7EAQlB0I4qJmHmzSpEk+derUZh4SCKWvr08nT560obK6ym5m90j6jaTRkl5y92dTj586darK5XI9hwSQUCqVKmY1v4w3s9GS1km6V9J0SYvMbHqtXw9AY9XzPXuHpM/c/ZC7n5b0B0nz8hkLQN7qKfu1kv486PMj2bYfMLOlZlY2s3J/f38dhwNQj3rKPtSbAD/62Vt373L3kruX2tra6jgcgHrUU/YjkqYM+nyypC/qGwdAo9RT9l2SbjCzn5rZGEkLJW3LZywAeav50pu7nzGzxyW9rYFLby+7+77cJgOQq7qus7v7W5LeymkWAA3Ej8sCQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQRF2ruKL1nT17Npl//fXXDT3+Cy+8UDH77rvvkvseOHAgma9bty6Zr1y5smK2efPm5L6XXHJJMl+1alUyX7NmTTIvQl1lN7M+Sd9IOivpjLuX8hgKQP7yOLPf6e4nc/g6ABqI79mBIOotu0v6k5ntNrOlQz3AzJaaWdnMyv39/XUeDkCt6i377e4+U9K9kpaZ2azzH+DuXe5ecvdSW1tbnYcDUKu6yu7uX2S3JyR1S+rIYygA+au57GY21szGn7svaa6kvXkNBiBf9bwbf7WkbjM793Vedff/yGWqEebw4cPJ/PTp08n8/fffT+Y7d+6smH311VfJfbdu3ZrMizR58uRkvnz58mTe3d1dMRs/fnxy31tvvTWZ33HHHcm8FdVcdnc/JCn9jABoGVx6A4Kg7EAQlB0IgrIDQVB2IAh+xTUHH3/8cTKfM2dOMm/0r5m2qlGj0ueaZ555JpmPHTs2mT/44IMVs2uuuSa574QJE5L5jTfemMxbEWd2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiC6+w5uO6665L5lVdemcxb+Tp7R0f675FUux69Y8eOitmYMWOS+y5evDiZ48JwZgeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBILjOnoOJEycm87Vr1ybzN998M5nPmDEjma9YsSKZ1/O1e3p6kvm4ceOS+d69lZcSeO6555L7Il+c2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCK6zN8H8+fOT+V133ZXMqy0v3NvbWzHbsGFDct/Ozs5kXu06ejU333xzxayrq6uur40LU/XMbmYvm9kJM9s7aNtEM+sxs4PZbfovGAAo3HBexm+UdM9521ZJ2u7uN0jann0OoIVVLbu7vyfp1Hmb50nalN3fJGl+vmMByFutb9Bd7e7HJCm7varSA81sqZmVzazc399f4+EA1Kvh78a7e5e7l9y91NbW1ujDAaig1rIfN7N2ScpuT+Q3EoBGqLXs2yQtye4vkfR6PuMAaJSq19nNbLOk2ZImmdkRSWskPStpi5k9IumwpJ83csiR7rLLLqtr/8svv7zmfV966aVkvnDhwmRebY11tI6qZXf3RRWiOTnPAqCB+G8ZCIKyA0FQdiAIyg4EQdmBIPgV1xFgzZo1FbPdu3cn93333XeT+TvvvJPM586dm8zROjizA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQXGcfAVJ/7nn9+vXJfWfOnJnMH3300WR+5513JvNSqVQxW7ZsWXJfM0vmuDCc2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCK6zj3DTpk1L5hs3bkzmDz/8cDJ/5ZVXas6//fbb5L4PPfRQMm9vb0/m+CHO7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBNfZg1uwYEEyv/7665N5Z2dnMt++fXvFbPXq1cl9P//882Rebf/Jkycn82iqntnN7GUzO2Fmewdte9rMjprZnuzjvsaOCaBew3kZv1HSPUNs/7W7z8g+3sp3LAB5q1p2d39P0qkmzAKggep5g+5xM+vNXuZPqPQgM1tqZmUzK/f399dxOAD1qLXsv5U0TdIMScck/bLSA929y91L7l5qa2ur8XAA6lVT2d39uLufdffvJa2X1JHvWADyVlPZzWzw7xYukLS30mMBtIaq19nNbLOk2ZImmdkRSWskzTazGZJcUp+kxxo3Iop0yy23JPMtW7Yk8zfeeKNiVu135V988cVkfvDgwWTe09OTzKOpWnZ3XzTE5g0NmAVAA/HjskAQlB0IgrIDQVB2IAjKDgRh7t60g5VKJS+Xy007HlrbxRdfnMzPnDmTzC+6KH0x6e23366YzZ49O7nv36pSqaRyuTzkWtec2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCP6UNJJ6e3uT+WuvvZbMd+3aVTGrdh29munTpyfzWbNm1fX1RxrO7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBNfZR7gDBw4k8+effz6Zd3d3J/Mvv/zygmcartGjRyfz9vb2ZD5qFOeywXg2gCAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIrrP/Dah2LfvVV1+tmK1bty65b19fXy0j5aJUKiXzp556Kpk/8MADeY4z4lU9s5vZFDPbYWb7zWyfma3Itk80sx4zO5jdTmj8uABqNZyX8Wckdbr7TZL+QdIyM5suaZWk7e5+g6Tt2ecAWlTVsrv7MXf/KLv/jaT9kq6VNE/SpuxhmyTNb9CMAHJwQW/QmdlUST+T9IGkq939mDTwH4Kkqyrss9TMymZW7u/vr3NcALUadtnNbJykrZJ+4e5/Ge5+7t7l7iV3L7W1tdUyI4AcDKvsZvYTDRT99+7+x2zzcTNrz/J2SScaMyKAPFS99GZmJmmDpP3u/qtB0TZJSyQ9m92+3pAJR4Djx48n83379iXzJ554Ipl/+umnFzxTXjo6OpL5k08+WTGbN29ecl9+RTVfw7nOfrukxZI+MbM92bbVGij5FjN7RNJhST9vyIQAclG17O6+U9KQi7tLmpPvOAAahddJQBCUHQiCsgNBUHYgCMoOBMGvuA7TqVOnKmaPPfZYct89e/Yk80OHDtUyUi5uu+22ZN7Z2ZnM77777mR+6aWXXvBMaAzO7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQRJjr7B988EEyX7t2bTL/8MMPK2ZHjx6taaa8pK5lL1++PLnv6tWrk/m4ceNqmgmthzM7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgQR5jp7d3d3XXk9brrppmR+//33J/PRo0cn85UrV1bMrrjiiuS+iIMzOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EYe6efoDZFEm/k/R3kr6X1OXuvzGzpyU9Kqk/e+hqd38r9bVKpZKXy+W6hwYwtFKppHK5POSqy8P5oZozkjrd/SMzGy9pt5n1ZNmv3f3f8xoUQOMMZ332Y5KOZfe/MbP9kq5t9GAA8nVB37Ob2VRJP5N07m88PW5mvWb2splNqLDPUjMrm1m5v79/qIcAaIJhl93MxknaKukX7v4XSb+VNE3SDA2c+X851H7u3uXuJXcvtbW11T8xgJoMq+xm9hMNFP337v5HSXL34+5+1t2/l7ReUkfjxgRQr6plNzOTtEHSfnf/1aDt7YMetkDS3vzHA5CX4bwbf7ukxZI+MbM92bbVkhaZ2QxJLqlPUnrdYgCFGs678TslDXXdLnlNHUBr4SfogCAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVT9U9K5HsysX9LngzZNknSyaQNcmFadrVXnkpitVnnOdp27D/n335pa9h8d3Kzs7qXCBkho1dladS6J2WrVrNl4GQ8EQdmBIIoue1fBx09p1dladS6J2WrVlNkK/Z4dQPMUfWYH0CSUHQiikLKb2T1mdsDMPjOzVUXMUImZ9ZnZJ2a2x8wKXV86W0PvhJntHbRtopn1mNnB7HbINfYKmu1pMzuaPXd7zOy+gmabYmY7zGy/me0zsxXZ9kKfu8RcTXnemv49u5mNlvTfkv5J0hFJuyQtcvf/auogFZhZn6SSuxf+AxhmNkvSXyX9zt1vzrb9m6RT7v5s9h/lBHf/1xaZ7WlJfy16Ge9staL2wcuMS5ov6V9U4HOXmOuf1YTnrYgze4ekz9z9kLuflvQHSfMKmKPluft7kk6dt3mepE3Z/U0a+MfSdBVmawnufszdP8rufyPp3DLjhT53ibmaooiyXyvpz4M+P6LWWu/dJf3JzHab2dKihxnC1e5+TBr4xyPpqoLnOV/VZbyb6bxlxlvmuatl+fN6FVH2oZaSaqXrf7e7+0xJ90palr1cxfAMaxnvZhlimfGWUOvy5/UqouxHJE0Z9PlkSV8UMMeQ3P2L7PaEpG613lLUx8+toJvdnih4nv/XSst4D7XMuFrguSty+fMiyr5L0g1m9lMzGyNpoaRtBczxI2Y2NnvjRGY2VtJctd5S1NskLcnuL5H0eoGz/ECrLONdaZlxFfzcFb78ubs3/UPSfRp4R/5/JD1VxAwV5vp7Sf+ZfewrejZJmzXwsu5/NfCK6BFJV0raLulgdjuxhWZ7RdInkno1UKz2gmb7Rw18a9graU/2cV/Rz11irqY8b/y4LBAEP0EHBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0H8H+uoNZJOrc9JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(255 - h, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e5be10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (np.round((datasets['train'][0][0]).reshape((28,28)).numpy())*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7acf1bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269ac13b1f0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(255 - h, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32910f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
