{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from fpga_nn_backend.datasets import *\n",
    "from fpga_nn_backend.training import *\n",
    "from fpga_nn_backend.evaluation import *\n",
    "from fpga_nn_backend.models.relu_toy_models import *\n",
    "from fpga_nn_backend.quantization import *\n",
    "from fpga_nn_backend.fpga_simple.emulation import *\n",
    "from fpga_nn_backend.fpga_simple.conversion import *\n",
    "from fpga_nn_backend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467669b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.10.0\n",
      "Torchvision Version: 0.11.1\n",
      "WARNING: Could not find GPU! Using CPU only\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebc2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = get_rel_pkg_path(\"dataset/\")\n",
    "weights_dir = get_rel_pkg_path(\"weights/\")\n",
    "session_dir = get_rel_pkg_path(\"sessions/\")\n",
    "models_dir = get_rel_pkg_path(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2143ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = ImageDatasetType.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bc6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_datasets = get_img_dataset(data_dir, dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6501354",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = apply_img_transforms(orig_datasets, dataset_type, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b031d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(datasets, 128, 128, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0769d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = IMG_DATASET_TO_IMG_SIZE_FLAT[dataset_type]\n",
    "num_classes = IMG_DATASET_TO_NUM_CLASSES[dataset_type]\n",
    "\n",
    "model = ReLUToyModel(input_dim, num_classes, layer_dims=[256, 128, 64, 32])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197f117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d09605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 256]         200,704\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "            Linear-4                  [-1, 128]          32,768\n",
      "              ReLU-5                  [-1, 128]               0\n",
      "            Linear-6                   [-1, 64]           8,192\n",
      "              ReLU-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,048\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             320\n",
      "     ReLUToyModel-11                   [-1, 10]               0\n",
      "      DeQuantStub-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 244,032\n",
      "Trainable params: 244,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 0.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f2857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-18-2021 11-04-36 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a69c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-20-2021 06-39-40 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6f35ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-23-2021 02-52-17 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_loss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0be415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 23.73it/s]\n",
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "#torch.quantization.fuse_modules(model.model.layers, [['0', '1'], ['2', '3'], ['4', '5'], ['6', '7']], inplace=True)\n",
    "model = torch.quantization.prepare(model)\n",
    "stats = get_dataloader_stats(dataloaders['test'], model, criterion, device)\n",
    "model_int8 = torch.quantization.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01a60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6ea8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantWrapper(\n",
       "  (model): ReLUToyModel(\n",
       "    (layers): Sequential(\n",
       "      (0): QuantizedLinear(in_features=784, out_features=256, scale=0.050842445343732834, zero_point=57, qscheme=torch.per_channel_affine)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): QuantizedLinear(in_features=256, out_features=128, scale=0.06895451247692108, zero_point=27, qscheme=torch.per_channel_affine)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): QuantizedLinear(in_features=128, out_features=64, scale=0.10227379202842712, zero_point=27, qscheme=torch.per_channel_affine)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): QuantizedLinear(in_features=64, out_features=32, scale=0.17031508684158325, zero_point=33, qscheme=torch.per_channel_affine)\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): QuantizedLinear(in_features=32, out_features=10, scale=0.40706461668014526, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "    )\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca02df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24, -36,  55,  ..., -34, -51,  18],\n",
       "        [ 66, -58,  62,  ...,   5, -62, -66],\n",
       "        [ 60, -87,  -6,  ...,  66,  17, -56],\n",
       "        ...,\n",
       "        [-41, -13,  41,  ...,  39,  57, -25],\n",
       "        [-32,  66, -31,  ..., -48,   5,  49],\n",
       "        [ 57, -51,  -4,  ..., -30, -18,  -3]], dtype=torch.int8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[0].weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c92e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8.model.layers[8].bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c0926ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:02<00:00, 27.69it/s]\n"
     ]
    }
   ],
   "source": [
    "stats = get_dataloader_stats(dataloaders['test'], model_int8, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f595a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6b47e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get_param(param):\n",
    "    if param is not None:\n",
    "        return param.int_repr().numpy()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5dbd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_nn = ConvertedNN((1, 28, 28))\n",
    "\n",
    "converted_nn.add_flatten_layer((1, 28, 28), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((784,), (256,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[0].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[0].bias()))\n",
    "converted_nn.add_relu_layer((256,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((256,), (128,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[2].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[2].bias()))\n",
    "converted_nn.add_relu_layer((128,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((128,), (64,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[4].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[4].bias()))\n",
    "converted_nn.add_relu_layer((64,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((64,), (32,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[6].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[6].bias()))\n",
    "converted_nn.add_relu_layer((32,), 0, 0)\n",
    "\n",
    "converted_nn.add_dense_layer((32,), (10,), 0, 0,\n",
    "    weight=safe_get_param(model_int8.model.layers[8].weight()),\n",
    "    bias=safe_get_param(model_int8.model.layers[8].bias()))\n",
    "\n",
    "converted_nn.add_output_layer((10,), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fea43ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedLinear(in_features=32, out_features=10, scale=0.40706461668014526, zero_point=64, qscheme=torch.per_channel_affine)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e1ab99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_nn.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1877a245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'layer_type': <ConverterLayerType.FLATTEN: 5>,\n",
       "   'input_shapes': ((1, 28, 28),),\n",
       "   'output_shape': (784,),\n",
       "   'output_size': 784,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <ConverterLayerType.DENSE: 0>,\n",
       "   'input_shapes': ((784,),),\n",
       "   'output_shape': (256,),\n",
       "   'output_size': 256,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <ConverterLayerType.RELU: 2>,\n",
       "   'input_shapes': ((256,),),\n",
       "   'output_shape': (256,),\n",
       "   'output_size': 256,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <ConverterLayerType.DENSE: 0>,\n",
       "   'input_shapes': ((256,),),\n",
       "   'output_shape': (128,),\n",
       "   'output_size': 128,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <ConverterLayerType.RELU: 2>,\n",
       "   'input_shapes': ((128,),),\n",
       "   'output_shape': (128,),\n",
       "   'output_size': 128,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <ConverterLayerType.DENSE: 0>,\n",
       "   'input_shapes': ((128,),),\n",
       "   'output_shape': (64,),\n",
       "   'output_size': 64,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <ConverterLayerType.RELU: 2>,\n",
       "   'input_shapes': ((64,),),\n",
       "   'output_shape': (64,),\n",
       "   'output_size': 64,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <ConverterLayerType.DENSE: 0>,\n",
       "   'input_shapes': ((64,),),\n",
       "   'output_shape': (32,),\n",
       "   'output_size': 32,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <ConverterLayerType.RELU: 2>,\n",
       "   'input_shapes': ((32,),),\n",
       "   'output_shape': (32,),\n",
       "   'output_size': 32,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None},\n",
       "  {'layer_type': <ConverterLayerType.DENSE: 0>,\n",
       "   'input_shapes': ((32,),),\n",
       "   'output_shape': (10,),\n",
       "   'output_size': 10,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': {'weight': 0},\n",
       "   'metadata': {'has_bias': False}},\n",
       "  {'layer_type': <ConverterLayerType.OUTPUT: 7>,\n",
       "   'input_shapes': ((10,),),\n",
       "   'output_shape': (10,),\n",
       "   'output_size': 10,\n",
       "   'stack_input_indices': (0,),\n",
       "   'stack_output_index': 0,\n",
       "   'parameters': None,\n",
       "   'metadata': None}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_nn.get_layer_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f24c45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.coe\", 'w') as f:\n",
    "    f.write(converted_nn.generate_parameter_coe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e32910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator = FPGAEmulator(converted_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "530cab97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_shape': (1, 28, 28),\n",
       " 'inital_input_addr': 0,\n",
       " 'layers': [{'layer_type': <LayerType.DENSE: 0>,\n",
       "   'config': {'has_bias': None,\n",
       "    'input_base_addr': 0,\n",
       "    'weight_base_addr': 0,\n",
       "    'bias_base_addr': None,\n",
       "    'output_base_addr': 784,\n",
       "    'm_size': 256,\n",
       "    'chw_size': 784}},\n",
       "  {'layer_type': <LayerType.MOVE: 5>,\n",
       "   'config': {'input_base_addr': 784,\n",
       "    'output_base_addr': 0,\n",
       "    'move_size': 256}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'config': {'input_base_addr': 0,\n",
       "    'output_base_addr': 0,\n",
       "    'n_size': 256,\n",
       "    'inplace': True}},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'config': {'has_bias': None,\n",
       "    'input_base_addr': 0,\n",
       "    'weight_base_addr': 0,\n",
       "    'bias_base_addr': None,\n",
       "    'output_base_addr': 256,\n",
       "    'm_size': 128,\n",
       "    'chw_size': 256}},\n",
       "  {'layer_type': <LayerType.MOVE: 5>,\n",
       "   'config': {'input_base_addr': 256,\n",
       "    'output_base_addr': 0,\n",
       "    'move_size': 128}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'config': {'input_base_addr': 0,\n",
       "    'output_base_addr': 0,\n",
       "    'n_size': 128,\n",
       "    'inplace': True}},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'config': {'has_bias': None,\n",
       "    'input_base_addr': 0,\n",
       "    'weight_base_addr': 0,\n",
       "    'bias_base_addr': None,\n",
       "    'output_base_addr': 128,\n",
       "    'm_size': 64,\n",
       "    'chw_size': 128}},\n",
       "  {'layer_type': <LayerType.MOVE: 5>,\n",
       "   'config': {'input_base_addr': 128, 'output_base_addr': 0, 'move_size': 64}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'config': {'input_base_addr': 0,\n",
       "    'output_base_addr': 0,\n",
       "    'n_size': 64,\n",
       "    'inplace': True}},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'config': {'has_bias': None,\n",
       "    'input_base_addr': 0,\n",
       "    'weight_base_addr': 0,\n",
       "    'bias_base_addr': None,\n",
       "    'output_base_addr': 64,\n",
       "    'm_size': 32,\n",
       "    'chw_size': 64}},\n",
       "  {'layer_type': <LayerType.MOVE: 5>,\n",
       "   'config': {'input_base_addr': 64, 'output_base_addr': 0, 'move_size': 32}},\n",
       "  {'layer_type': <LayerType.RELU: 2>,\n",
       "   'config': {'input_base_addr': 0,\n",
       "    'output_base_addr': 0,\n",
       "    'n_size': 32,\n",
       "    'inplace': True}},\n",
       "  {'layer_type': <LayerType.DENSE: 0>,\n",
       "   'config': {'has_bias': None,\n",
       "    'input_base_addr': 0,\n",
       "    'weight_base_addr': 0,\n",
       "    'bias_base_addr': None,\n",
       "    'output_base_addr': 32,\n",
       "    'm_size': 10,\n",
       "    'chw_size': 32}},\n",
       "  {'layer_type': <LayerType.MOVE: 5>,\n",
       "   'config': {'input_base_addr': 32, 'output_base_addr': 0, 'move_size': 10}},\n",
       "  {'layer_type': <LayerType.OUTPUT: 6>, 'config': {'output_base_addr': 0}}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator.exec_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fdd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
