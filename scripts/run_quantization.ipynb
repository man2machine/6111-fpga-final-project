{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "from fpga_nn_backend.datasets import *\n",
    "from fpga_nn_backend.training import *\n",
    "from fpga_nn_backend.evaluation import *\n",
    "from fpga_nn_backend.models.relu_toy_models import *\n",
    "from fpga_nn_backend.quantization import *\n",
    "from fpga_nn_backend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467669b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.10.0\n",
      "Torchvision Version: 0.11.1\n",
      "WARNING: Could not find GPU! Using CPU only\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebc2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = get_rel_pkg_path(\"dataset/\")\n",
    "weights_dir = get_rel_pkg_path(\"weights/\")\n",
    "session_dir = get_rel_pkg_path(\"sessions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2143ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = ImageDatasetType.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bc6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_datasets = get_img_dataset(data_dir, dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6501354",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = apply_img_transforms(orig_datasets, dataset_type, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b031d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_dataloaders(datasets, 128, 128, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0769d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = IMG_DATASET_TO_IMG_SIZE_FLAT[dataset_type]\n",
    "num_classes = IMG_DATASET_TO_NUM_CLASSES[dataset_type]\n",
    "\n",
    "model = ReLUToyModel(input_dim, num_classes, layer_dims=[256, 128, 64, 32])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b9c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]         200,704\n",
      "              ReLU-2                  [-1, 256]               0\n",
      "            Linear-3                  [-1, 128]          32,768\n",
      "              ReLU-4                  [-1, 128]               0\n",
      "            Linear-5                   [-1, 64]           8,192\n",
      "              ReLU-6                   [-1, 64]               0\n",
      "            Linear-7                   [-1, 32]           2,048\n",
      "              ReLU-8                   [-1, 32]               0\n",
      "            Linear-9                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 244,042\n",
      "Trainable params: 244,042\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 0.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "197f117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d09605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 256]         200,704\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "            Linear-4                  [-1, 128]          32,768\n",
      "              ReLU-5                  [-1, 128]               0\n",
      "            Linear-6                   [-1, 64]           8,192\n",
      "              ReLU-7                   [-1, 64]               0\n",
      "            Linear-8                   [-1, 32]           2,048\n",
      "              ReLU-9                   [-1, 32]               0\n",
      "           Linear-10                   [-1, 10]             330\n",
      "     ReLUToyModel-11                   [-1, 10]               0\n",
      "      DeQuantStub-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 244,042\n",
      "Trainable params: 244,042\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.93\n",
      "Estimated Total Size (MB): 0.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (input_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f2857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-18-2021 11-04-36 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a69c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(weights_dir, r\"Experiment 11-20-2021 06-39-40 PM\\Weights Best.pckl\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_loss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae28fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=256, bias=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d0be415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [00:03<00:00, 22.15it/s]\n",
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "C:\\Users\\Shahir\\anaconda3\\envs\\py3-dl\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    }
   ],
   "source": [
    "model_fp32 = model\n",
    "model_fp32.eval()\n",
    "model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "model_fp32_prepared = torch.quantization.prepare(model_fp32)\n",
    "stats = get_dataloader_stats(dataloaders['test'], model_fp32_prepared, criterion, device)\n",
    "model_int8 = torch.quantization.convert(model_fp32_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01a60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9241\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", stats['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca02df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  80,   -5,   33,  115,   21,  -38,   72,  -13, -106,   18,   19,   12,\n",
       "           53,  -36,   48,   25,   30,  -99,  -32,   59,   37,  -42, -103,  -62,\n",
       "         -128,   27,   -7,   99,   71,   -8,  -42,   75],\n",
       "        [ -56,    2,  -75,   -3,   24,  -33,    4,   26,   81,   69,   30,  -86,\n",
       "          -86,  -92,  -42,  -18,   14,   26,  -36,  -30,  -69,   34,   51,   75,\n",
       "          127,  -11,   27,  -68,  -53,  -29,   -6,  -61],\n",
       "        [ -30,   63,   71,   59,   38,  -38,    9,   43,   69,  -19,   12,  -47,\n",
       "          -60,  -48,   22,  -94,  127,  -87, -111,  102,  -66,  -23,  -82,   22,\n",
       "           94,   -2,   34,   60,   20,  -10, -108,  -16],\n",
       "        [ -38,    4,  -70, -109,  127,  -41,   40,    3,   76,  -40,  -44,  -65,\n",
       "           33, -104,  103,   48,    6,  -44,    8,   74,   52,   84,   28,  -62,\n",
       "           12,  -19,  -27,    0,  -63,  -19,  -39,   32],\n",
       "        [ -67,    7,   76,   10, -128,   -5,   26,   18,  -15,    2,  -27,   11,\n",
       "            7,   87,   -9,  -17,  -25,   73,   83,  -92,  -24,  -21,   34,   24,\n",
       "          -11,  -34,   14,  -72,   59,   21,   18,  -51],\n",
       "        [ -42,  -78,   12,  -69,   34,   57,  -90,   30, -121,  -18,    7,  -93,\n",
       "           83,   24,  123,  127,    3,  -42,   87,   35,  116,   41,  -33,  -92,\n",
       "          -87,  -25,  -39,   35,   43,   43,  104,   44],\n",
       "        [ -10,  -44,   67,   22,  -51,    1,   13,  -14,  -40,  -24,   -4,  -70,\n",
       "           11,    1,  -23,   39,  127,  -37,   73,  -23,   -8,  -93,  -77,  -43,\n",
       "          -36,    9,   35,    2,   59,    5,   47,  -87],\n",
       "        [ -26,   54,  -45,   51,  -25,    0,   13,    8,   64,  -11,  -25,   53,\n",
       "            4,   39,    6,  -48, -128,   36,  -57,   10,   36,   59,   20,   57,\n",
       "          -29,  -21,   26,  -35,  -17,   -4,  -81,   63],\n",
       "        [ 127,  -92,   25,  -87,   21,   -4,    4,  -18,  -41,  -39,  -40,   -7,\n",
       "          -84,  -54,  -90,  -54,   63,    0,   20,    5,   36,   69,   29,   75,\n",
       "           18,   33,  -35,  -38,   24,   26,   29,  -33],\n",
       "        [   4,   52,   10,  -45,  -74,   23,  -12,    9,  -12,   10,   39,  127,\n",
       "          -18,   26,  -42,   32,  -76,    9,  -35,    8,  -14,   13,   89,   35,\n",
       "            4,   34,   18,  -43,   30,    6,   27,   32]], dtype=torch.int8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8.model.layers[8].weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0926ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_dataloader_stats(dataloaders['test'], model_int8, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5403414",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_int8.state_dict(), \"Asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87119b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
